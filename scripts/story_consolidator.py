#!/usr/bin/env python3
"""
æ•…äº‹æ•´åˆå™¨ - å°†æ‰€æœ‰LLMç”Ÿæˆçš„æ•…äº‹æ•´åˆåˆ°æ¸¸æˆæ•°æ®ä¸­
"""

import os
import json
from pathlib import Path
from datetime import datetime

class StoryConsolidator:
    def __init__(self):
        self.stories_dir = Path('frontend/src/data/stories')
        self.output_file = Path('frontend/src/data/consolidated-stories.json')
        self.index_file = Path('frontend/src/data/story-index.json')

    def consolidate_all_stories(self):
        """æ•´åˆæ‰€æœ‰æ•…äº‹"""
        all_stories = {}
        story_index = {
            'total_stories': 0,
            'by_type': {},
            'last_updated': datetime.now().isoformat(),
            'categories': []
        }

        # éå†æ‰€æœ‰æ•…äº‹ç±»å‹ç›®å½•
        for story_type_dir in self.stories_dir.iterdir():
            if not story_type_dir.is_dir():
                continue
                
            story_type = story_type_dir.name
            stories = []
            
            # è¯»å–è¯¥ç±»å‹çš„æ‰€æœ‰æ•…äº‹
            for story_file in story_type_dir.glob('*.json'):
                try:
                    with open(story_file, 'r', encoding='utf-8') as f:
                        story_data = json.load(f)
                        stories.append(story_data)
                except Exception as e:
                    print(f"è¯»å–æ•…äº‹æ–‡ä»¶å¤±è´¥ {story_file}: {e}")
            
            if stories:
                all_stories[story_type] = stories
                story_index['by_type'][story_type] = len(stories)
                story_index['total_stories'] += len(stories)
                story_index['categories'].append({
                    'type': story_type,
                    'count': len(stories),
                    'description': self.get_type_description(story_type)
                })
                
                print(f"ğŸ“š æ•´åˆ {story_type}: {len(stories)} ä¸ªæ•…äº‹")

        # ä¿å­˜æ•´åˆåçš„æ•…äº‹
        with open(self.output_file, 'w', encoding='utf-8') as f:
            json.dump(all_stories, f, ensure_ascii=False, indent=2)
        
        # ä¿å­˜ç´¢å¼•
        with open(self.index_file, 'w', encoding='utf-8') as f:
            json.dump(story_index, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… æ•´åˆå®Œæˆ: {story_index['total_stories']} ä¸ªæ•…äº‹")
        return story_index

    def get_type_description(self, story_type):
        """è·å–æ•…äº‹ç±»å‹æè¿°"""
        descriptions = {
            'main_quest': 'ä¸»çº¿å‰§æƒ… - å²è¯—çº§çš„æ±Ÿæ¹–å¤§äº‹',
            'side_quest': 'æ”¯çº¿ä»»åŠ¡ - æœ‰è¶£çš„å°æ•…äº‹å’Œä»»åŠ¡',
            'npc_stories': 'NPCæ•…äº‹ - ä¸°å¯Œçš„è§’è‰²èƒŒæ™¯',
            'sect_events': 'é—¨æ´¾äº‹ä»¶ - é—¨æ´¾ç›¸å…³çš„å‰§æƒ…',
            'romance_plots': 'æƒ…æ„Ÿå‰§æƒ… - æ±Ÿæ¹–å„¿å¥³æƒ…é•¿',
            'mystery_cases': 'æ‚¬ç–‘æ¡ˆä»¶ - æ‰‘æœ”è¿·ç¦»çš„è°œå›¢',
            'martial_legends': 'æ­¦åŠŸä¼ è¯´ - ç»ä¸–æ­¦åŠŸçš„æ•…äº‹',
            'world_events': 'ä¸–ç•Œäº‹ä»¶ - å½±å“æ±Ÿæ¹–çš„å¤§äº‹ä»¶'
        }
        return descriptions.get(story_type, 'æœªçŸ¥ç±»å‹')

if __name__ == '__main__':
    consolidator = StoryConsolidator()
    consolidator.consolidate_all_stories()
